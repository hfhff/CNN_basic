{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Training with CIFAR10 - Dataset Load & Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets as D\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform_train = T.Compose([\n",
    "    T.RandomCrop(32, padding=4), # random한 위치에서 crop 진행(32 size, 모든 경계에 padding)\n",
    "    T.RandomHorizontalFlip(), \n",
    "    T.RandomRotation(15), # -15~15도 내에서 회전\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2), # hue: 0~255의 컬러 #saturarion: hue의 순수도 contrast: 명암\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "batch_size = 128 # 이미지 묶음 당 이미지 개수\n",
    "\n",
    "#CIFAR10 - 10개 클래스, 32x32x3 이미지\n",
    "\n",
    "#train data 정의\n",
    "trainset = D.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train) \n",
    "\n",
    "# trainloader를 통해 train_data를 load\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "#test data 정의\n",
    "testset = D.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "train_size = int(0.8 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_dataset, val_dataset = random_split(trainset, [train_size, val_size])\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained model - VGG16bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "vgg16_bn_model = models.vgg16_bn(pretrained = True)\n",
    "vgg16_bn_model.classifier[6] = nn.Linear(in_features=4096, out_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = vgg16_bn_model.to(device)\n",
    "def training(model, trainloader):\n",
    "    num_epoch = 200\n",
    "    total_step = len(trainloader)\n",
    "    epoch_losses = []\n",
    "    learning_rate = 1e-4\n",
    "    momentum_value = 0.9\n",
    "    weight_decay_value = 1e-4\n",
    "    patience = 20\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss() #loss function 설정\n",
    "    optimizer = optim.Adam(vgg16_bn_model.parameters(), lr=learning_rate, weight_decay = weight_decay_value) \n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(trainloader), epochs=100)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in trainloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_loss = running_loss / len(trainloader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Epoch {epoch+1}/{num_epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "        early_stopping(val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.0191, Val Loss: 0.7110\n",
      "Epoch 2/100, Train Loss: 0.6852, Val Loss: 0.5862\n",
      "Epoch 3/100, Train Loss: 0.5976, Val Loss: 0.5356\n",
      "Epoch 4/100, Train Loss: 0.5309, Val Loss: 0.4607\n",
      "Epoch 5/100, Train Loss: 0.4838, Val Loss: 0.4242\n",
      "Epoch 6/100, Train Loss: 0.4558, Val Loss: 0.4516\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 7/100, Train Loss: 0.4388, Val Loss: 0.4449\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 8/100, Train Loss: 0.4144, Val Loss: 0.3505\n",
      "Epoch 9/100, Train Loss: 0.3995, Val Loss: 0.3774\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 10/100, Train Loss: 0.4013, Val Loss: 0.4129\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 11/100, Train Loss: 0.4003, Val Loss: 0.3224\n",
      "Epoch 12/100, Train Loss: 0.3455, Val Loss: 0.3764\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 13/100, Train Loss: 0.6343, Val Loss: 0.4270\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 14/100, Train Loss: 0.4036, Val Loss: 0.3492\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 15/100, Train Loss: 0.3362, Val Loss: 0.2721\n",
      "Epoch 16/100, Train Loss: 0.3901, Val Loss: 0.2821\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 17/100, Train Loss: 0.3085, Val Loss: 0.2822\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 18/100, Train Loss: 0.2977, Val Loss: 0.2557\n",
      "Epoch 19/100, Train Loss: 0.2833, Val Loss: 0.2705\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 20/100, Train Loss: 0.4125, Val Loss: 0.6091\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 21/100, Train Loss: 0.3934, Val Loss: 0.2795\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 22/100, Train Loss: 0.2898, Val Loss: 0.2523\n",
      "Epoch 23/100, Train Loss: 0.2698, Val Loss: 0.2223\n",
      "Epoch 24/100, Train Loss: 0.2572, Val Loss: 0.2256\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 25/100, Train Loss: 0.2691, Val Loss: 0.2107\n",
      "Epoch 26/100, Train Loss: 0.3386, Val Loss: 0.4129\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 27/100, Train Loss: 0.3894, Val Loss: 0.2747\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 28/100, Train Loss: 0.2723, Val Loss: 0.2119\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 29/100, Train Loss: 0.2413, Val Loss: 0.2092\n",
      "Epoch 30/100, Train Loss: 0.2319, Val Loss: 0.1975\n",
      "Epoch 31/100, Train Loss: 0.2383, Val Loss: 0.2241\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 32/100, Train Loss: 0.2396, Val Loss: 0.2089\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 33/100, Train Loss: 0.2309, Val Loss: 0.2264\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 34/100, Train Loss: 0.2585, Val Loss: 0.3331\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 35/100, Train Loss: 0.3311, Val Loss: 0.2493\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 36/100, Train Loss: 0.2439, Val Loss: 0.1990\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 37/100, Train Loss: 0.2082, Val Loss: 0.1895\n",
      "Epoch 38/100, Train Loss: 0.2023, Val Loss: 0.1670\n",
      "Epoch 39/100, Train Loss: 0.2078, Val Loss: 0.2089\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 40/100, Train Loss: 0.2073, Val Loss: 0.1680\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 41/100, Train Loss: 0.2066, Val Loss: 0.1782\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 42/100, Train Loss: 0.2016, Val Loss: 0.1726\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 43/100, Train Loss: 0.2090, Val Loss: 0.1929\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 44/100, Train Loss: 0.2162, Val Loss: 0.1840\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 45/100, Train Loss: 0.1963, Val Loss: 0.1524\n",
      "Epoch 46/100, Train Loss: 0.1933, Val Loss: 0.2006\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 47/100, Train Loss: 0.1958, Val Loss: 0.1565\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 48/100, Train Loss: 0.1856, Val Loss: 0.1792\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 49/100, Train Loss: 0.1922, Val Loss: 0.1812\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 50/100, Train Loss: 0.2088, Val Loss: 0.1599\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 51/100, Train Loss: 0.1773, Val Loss: 0.1613\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 52/100, Train Loss: 0.1759, Val Loss: 0.1612\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 53/100, Train Loss: 0.1797, Val Loss: 0.1478\n",
      "Epoch 54/100, Train Loss: 0.1744, Val Loss: 0.1602\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 55/100, Train Loss: 0.1765, Val Loss: 0.1358\n",
      "Epoch 56/100, Train Loss: 0.1692, Val Loss: 0.1449\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 57/100, Train Loss: 0.1701, Val Loss: 0.1523\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 58/100, Train Loss: 0.1681, Val Loss: 0.1551\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 59/100, Train Loss: 0.1905, Val Loss: 0.1635\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 60/100, Train Loss: 0.1675, Val Loss: 0.1437\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 61/100, Train Loss: 0.1691, Val Loss: 0.1355\n",
      "Epoch 62/100, Train Loss: 0.1654, Val Loss: 0.1505\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 63/100, Train Loss: 0.1584, Val Loss: 0.1366\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 64/100, Train Loss: 0.1636, Val Loss: 0.1341\n",
      "Epoch 65/100, Train Loss: 0.1586, Val Loss: 0.1488\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 66/100, Train Loss: 0.1609, Val Loss: 0.1469\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 67/100, Train Loss: 0.1590, Val Loss: 0.1622\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 68/100, Train Loss: 0.1612, Val Loss: 0.1416\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 69/100, Train Loss: 0.1547, Val Loss: 0.1632\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 70/100, Train Loss: 0.1552, Val Loss: 0.1524\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 71/100, Train Loss: 0.1541, Val Loss: 0.1468\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 72/100, Train Loss: 0.1612, Val Loss: 0.1531\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 73/100, Train Loss: 0.1544, Val Loss: 0.1291\n",
      "Epoch 74/100, Train Loss: 0.1517, Val Loss: 0.1253\n",
      "Epoch 75/100, Train Loss: 0.1498, Val Loss: 0.1454\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 76/100, Train Loss: 0.1434, Val Loss: 0.1337\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 77/100, Train Loss: 0.1459, Val Loss: 0.1221\n",
      "Epoch 78/100, Train Loss: 0.1474, Val Loss: 0.1292\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 79/100, Train Loss: 0.1443, Val Loss: 0.1280\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 80/100, Train Loss: 0.1444, Val Loss: 0.1159\n",
      "Epoch 81/100, Train Loss: 0.1479, Val Loss: 0.0997\n",
      "Epoch 82/100, Train Loss: 0.1484, Val Loss: 0.1410\n",
      "EarlyStopping counter: 1 out of 20\n",
      "Epoch 83/100, Train Loss: 0.1461, Val Loss: 0.1092\n",
      "EarlyStopping counter: 2 out of 20\n",
      "Epoch 84/100, Train Loss: 0.1455, Val Loss: 0.1132\n",
      "EarlyStopping counter: 3 out of 20\n",
      "Epoch 85/100, Train Loss: 0.1384, Val Loss: 0.1072\n",
      "EarlyStopping counter: 4 out of 20\n",
      "Epoch 86/100, Train Loss: 0.1361, Val Loss: 0.1320\n",
      "EarlyStopping counter: 5 out of 20\n",
      "Epoch 87/100, Train Loss: 0.1359, Val Loss: 0.1264\n",
      "EarlyStopping counter: 6 out of 20\n",
      "Epoch 88/100, Train Loss: 0.1416, Val Loss: 0.1134\n",
      "EarlyStopping counter: 7 out of 20\n",
      "Epoch 89/100, Train Loss: 0.1423, Val Loss: 0.1163\n",
      "EarlyStopping counter: 8 out of 20\n",
      "Epoch 90/100, Train Loss: 0.1405, Val Loss: 0.1181\n",
      "EarlyStopping counter: 9 out of 20\n",
      "Epoch 91/100, Train Loss: 0.1375, Val Loss: 0.1200\n",
      "EarlyStopping counter: 10 out of 20\n",
      "Epoch 92/100, Train Loss: 0.1346, Val Loss: 0.1024\n",
      "EarlyStopping counter: 11 out of 20\n",
      "Epoch 93/100, Train Loss: 0.1355, Val Loss: 0.1218\n",
      "EarlyStopping counter: 12 out of 20\n",
      "Epoch 94/100, Train Loss: 0.1337, Val Loss: 0.1412\n",
      "EarlyStopping counter: 13 out of 20\n",
      "Epoch 95/100, Train Loss: 0.1385, Val Loss: 0.1357\n",
      "EarlyStopping counter: 14 out of 20\n",
      "Epoch 96/100, Train Loss: 0.1359, Val Loss: 0.1241\n",
      "EarlyStopping counter: 15 out of 20\n",
      "Epoch 97/100, Train Loss: 0.1356, Val Loss: 0.1116\n",
      "EarlyStopping counter: 16 out of 20\n",
      "Epoch 98/100, Train Loss: 0.1339, Val Loss: 0.1053\n",
      "EarlyStopping counter: 17 out of 20\n",
      "Epoch 99/100, Train Loss: 0.1340, Val Loss: 0.1228\n",
      "EarlyStopping counter: 18 out of 20\n",
      "Epoch 100/100, Train Loss: 0.1318, Val Loss: 0.1231\n",
      "EarlyStopping counter: 19 out of 20\n"
     ]
    }
   ],
   "source": [
    "training(model, trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in testloader:\n",
    "            images, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct // total:.4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 91.0000 %\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model=cnn_model.to(device)\n",
    "inference(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
